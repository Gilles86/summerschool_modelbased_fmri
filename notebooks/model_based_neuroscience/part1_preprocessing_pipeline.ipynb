{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing fMRI data with Nipype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will preprocess data with the standard FSL pipeline, using [Nipype](http://nipy.sourceforge.net/nipype/index.html).\n",
    "\n",
    "Nipype is a pipelining tool that makes it easy to share pipelines of fMRI preprocessing, as well as document them, and run (them in parallel on the cluster)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named seaborn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e711482a5f4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Seaborn is an extension to matplotlib, that offers convenience wrappers and less ugly plots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named seaborn"
     ]
    }
   ],
   "source": [
    "# Nipype is a pipelining tool\n",
    "import nipype\n",
    "\n",
    "# Nibabel is a library to read in nifti-files\n",
    "import nibabel as nb\n",
    "\n",
    "# Numpy is 'matlab for Python'\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib is a plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seaborn is an extension to matplotlib, that offers convenience wrappers and less ugly plots\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to plot the pictures 'inline': in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = nb.load('/data/func_raw/pp0197/pp0197_B1.nii.gz').get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now \n",
    "\n",
    "[code]data[/code] \n",
    "\n",
    "is a numpy-array: a matlab-like matrix, that is efficiently stored in memory, and can be accessed fast using pointers.\n",
    "\n",
    "1) What is the size of this matrix ([hint](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html))?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Try to average the data over the time-dimension (last-dimension; [hint](http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_data = # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use the following code to make an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(mean_data[:, 40, :,].T, origin='lower', cmap=plt.cm.gray, interpolation='nearest')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an 'coronal' slice. Can you edit the code to make an _axial_ slice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load some pipelining libraries\n",
    "from nipype.workflows.fmri.fsl import create_featreg_preproc\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.io as nio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we start with the real pipelining. Crucial for this is to understand the _data structure_. Ipython notebook makes it possible to run shell ('linux') commands, like _ls_, that show the contents of a directory.\n",
    "\n",
    "This are the directories that containt the 'raw' fMRI files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pp0197\tpp0381\tpp0483\tpp0523\tpp0544\tpp0549\tpp0552\tpp0554\tpp0558\r\n",
      "pp0372\tpp0471\tpp0498\tpp0538\tpp0548\tpp0551\tpp0553\tpp0555\tpp0559\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data/func_raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pp0197_B1.nii.gz  pp0197_B2.nii.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls /data/func_raw/pp0197/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you draw a little sketch of how these directories look like? Can you show the contents of a different directory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now set up the standard fsl preprocessing workflow, and set the smoothing to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create workflow\n",
    "preproc_workflow = create_featreg_preproc()\n",
    "\n",
    "\n",
    "# Put the temprarory 'workflow-folder' on the big /data-disk!!\n",
    "preproc_workflow.base_dir = '/data/workflow_folders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up smoothing and highpass filtering at 64 seconds\n",
    "TR = 2.0\n",
    "preproc_workflow.inputs.inputspec.fwhm = 0.0\n",
    "preproc_workflow.inputs.inputspec.highpass = 64 / TR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to make a template of how the functional files look like.  Have a look at the documentation for the [SelectFiles-interface](http://nipy.sourceforge.net/nipype/interfaces/generated/nipype.interfaces.io.html#nipype-interfaces-io-selectfiles)\n",
    "\n",
    "Can you fill in the {subject_id}-variable at the right spots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "templates = {'func':'/data/func_raw/ .... _B*.nii.gz'} # fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a file-selector with this template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selector = pe.Node(nio.SelectFiles(templates), name='selector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we connect the selector to the input of the preprocessing workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc_workflow.connect(selector, 'func', preproc_workflow.get_node(\"inputspec\"), 'func')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Fill in the first 4 subject_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector.iterables = [('subject_id', ['0197', ...])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = pe.Node(nio.DataSink(), name='datasink')\n",
    "ds.inputs.base_directory = '/data/preprocessed_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) We now make a datasink that collects the output of the workflow and writes it to a final directory. Can you make sure all the outputs get written to the datasink ('/data/preprocessed_data/')?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "highpassed_files = None\n",
       "mask = None\n",
       "mean = None\n",
       "motion_parameters = None\n",
       "motion_plots = None\n",
       "realigned_files = None\n",
       "reference = None\n",
       "smoothed_files = None"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_workflow.outputs.outputspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc_workflow.connect(preproc_workflow.get_node(\"outputspec\"), 'highpassed_files', ds, 'highpassed_files')\n",
    "# ... FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice feature of nipype is to draw a graph of a workflow. Can you make it appear? (Hint: add a .png to the dot-file, or use 'ls' to see what exactly happened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "preproc_workflow.write_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(# FILL IN ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to run the workflow! Using the 'MultiProc'-plugin we can run the workflow in parallel on multiple cores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc_workflow.run(plugin='MultiProc', plugin_args={'n_procs' : 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep this window open! While the pipeline is running, you can start with the [next lesson](./part2_hddm.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
